\chapter{Some Not-so-crazy Math}

\section{Total and Partial Derivatives}
To understand the different kinds of derivatives, let's say we have a function $\rho(t, x(t), p(t))$ which, in general, depends on the location $x(t)$ and momentum $p(t)$ plus the time $t.$ A key observation is that the location $x(t)$ and momentum $p(t)$ are functions of $t$ too. Therefore, we need to be extremely careful what we mean when we calculate the derivative with respect to the time $t .$
$$
\frac{d \rho}{d t}=\lim _{\Delta t \rightarrow 0} \frac{\rho(t+\Delta t, x(t+\Delta t), p(t+\Delta t))-\rho(t, x(t), p(t))}{\Delta t}
$$
\textbf{The result is the total rate of change of $\rho$}.
$$
\frac{\partial \rho}{\partial t}=\lim _{\Delta t \rightarrow 0} \frac{\rho(t+\Delta t, x(t), p(t))-\rho(t, x(t), p(t))}{\Delta t}
$$
The key difference is that we only vary $t$ if it appears explicitly
in $\rho$ but not if it only appears implicitly because $x(t)$ and $p(t)$
also depend on $t .$ Thus
$$
\frac{d \rho}{d t}=\frac{\partial \rho}{\partial x} \frac{d x}{d t}+\frac{\partial \rho}{\partial p} \frac{d p}{d t}+\frac{\partial \rho}{\partial t}
$$
\section{Taylor Expansion}
In general, we want to estimate the value of some function $f(x)$ at some value of $x$ by using our knowledge of the function's value at some fixed point $a .$ The Taylor series then reads
\begin{equation}
\begin{aligned}
f(x)=& \sum_{n=0}^{\infty} \frac{f^{(n)}(a)(x-a)^{n}}{n !} \\
=& \frac{f^{(0)}(a)(x-a)^{0}}{0 !}+\frac{f^{(1)}(a)(x-a)^{1}}{1 !}+\frac{f^{(2)}(a)(x-a)^{2}}{2 !} \\
&+\frac{f^{(3)}(a)(x-a)^{3}}{3 !}+\ldots
\end{aligned}
\end{equation}
or
\begin{equation}
f(x+a)=f(x)+(a \cdot \partial) f(x)+\frac{1}{2}(a \cdot \partial)^{2} f(x)+\cdots
\end{equation}
Taylor expansion of a scalar field (function $f$ that maps $\mathbb{R}^{n}$ to $\mathbb{R}$).Now, identify $\partial f / \partial t$ as $\hat{\boldsymbol{n}} \cdot \nabla f .$ In addition, see that $t \hat{\boldsymbol{n}}=\boldsymbol{x}-\boldsymbol{x}_{0} .$ Some clever recombining of terms gives
\begin{equation}
f(x)=f\left(x_{0}\right)+\left.\left(x-x_{0}\right) \cdot \nabla f\right|_{x_{0}}+\left.\frac{1}{2}\left(\left[x-x_{0}\right] \cdot \nabla\right)^{2} f\right|_{x_{0}}+\ldots
\end{equation}
and
\begin{equation}
\hat{\boldsymbol{n}} \cdot \nabla=\partial_{t}
\end{equation}

\section{Vector Identities}
\begin{equation}
\begin{aligned}
&\vec{\nabla} \cdot(\vec{\nabla} \times \vec{A}) \equiv \operatorname{div}(\operatorname{rot} \vec{A})=(\vec{\nabla} \times \vec{\nabla}) \cdot \vec{A} \equiv 0\\
&\vec{\nabla} \times(\vec{\nabla} \varphi) \equiv \operatorname{rot} \operatorname{grad} \varphi=(\vec{\nabla} \times \vec{\nabla}) \varphi \equiv 0
\end{aligned}
\end{equation}
\begin{equation}
\begin{aligned}
&\vec{\nabla} \cdot(\vec{A} \varphi)=\varphi \vec{\nabla} \cdot \vec{A}+\vec{A} \cdot \vec{\nabla} \varphi \quad \Longleftrightarrow \quad \operatorname{div}(\vec{A} \varphi)=\varphi \operatorname{div} \vec{A}+\vec{A} \cdot \operatorname{grad} \varphi\\
&\vec{\nabla} \times(\vec{A} \varphi)=\varphi \vec{\nabla} \times \vec{A}-\vec{A} \times \vec{\nabla} \varphi \quad \Longleftrightarrow \quad \operatorname{rot}(\vec{A} \varphi)=\varphi \operatorname{rot} \vec{A}-\vec{A} \times \operatorname{grad} \varphi\\
&\vec{\nabla} \cdot(\vec{A} \times \vec{B})=\vec{B} \cdot(\vec{\nabla} \times \vec{A})-\vec{A} \cdot(\vec{\nabla} \times \vec{B}) \quad \Longleftrightarrow \quad \operatorname{div}(\vec{A} \times \vec{B})=\vec{B} \cdot \operatorname{rot} \vec{A}-\vec{A} \cdot \operatorname{rot} \vec{B}
\end{aligned}
\end{equation}
\begin{equation}
\begin{aligned}
\vec{\nabla} \times(\vec{A} \times \vec{B}) &=(\vec{B} \cdot \vec{\nabla}) \vec{A}-(\vec{A} \cdot \vec{\nabla}) \vec{B}+\vec{A}(\vec{\nabla} \cdot \vec{B})-\vec{B}(\vec{\nabla} \cdot \vec{A}) \\
& \Longleftrightarrow \operatorname{rot}(\vec{A} \times \vec{B})=(\vec{B} \operatorname{grad}) \vec{A}-(\vec{A} \operatorname{grad}) \vec{B}+\vec{A}(\operatorname{div} \vec{B})-\vec{B}(\operatorname{div} \vec{A})
\end{aligned}
\end{equation}
\begin{equation}
\begin{aligned}
\vec{\nabla}(\vec{A} \cdot \vec{B})=&(\vec{B} \cdot \vec{\nabla}) \vec{A}+(\vec{A} \cdot \vec{\nabla}) \vec{B}+\vec{A} \times(\vec{\nabla} \times \vec{B})+\vec{B} \times(\vec{\nabla} \times \vec{A}) \\
& \Longleftrightarrow \operatorname{grad}(\vec{A} \cdot \vec{B})=(\vec{B} \cdot \operatorname{grad}) \vec{A}+(\vec{A} \cdot \operatorname{grad}) \vec{B}+\vec{A} \times \operatorname{rot} \vec{B}+\vec{B} \times \operatorname{rot} \vec{A}
\end{aligned}
\end{equation}
\begin{equation}
\begin{aligned}
&\vec{\nabla} \cdot(\vec{\nabla} \varphi) \equiv \operatorname{div}(\operatorname{grad} \varphi) \equiv \Delta \varphi=\frac{\partial^{2} \varphi}{\partial x^{2}}+\frac{\partial^{2} \varphi}{\partial y^{2}}+\frac{\partial^{2} \varphi}{\partial z^{2}}, \quad \Delta=\text { Laplace Operator }\\
&\vec{\nabla} \times(\vec{\nabla} \times \vec{A}) \equiv \operatorname{rot}(\operatorname{rot} \vec{A})=\vec{\nabla}(\vec{\nabla} \cdot \vec{A})-(\vec{\nabla} \cdot \vec{\nabla}) \vec{A} \equiv \operatorname{grad} \operatorname{div} \vec{A}-\Delta \vec{A}
\end{aligned}
\end{equation}

\section{Tensor Algebra and Analysis}
\subsection{Linear Spaces, Vectors, and Tensors}
The linear space, say $L$, consists of the elements (vectors) that \textbf{permit linear operations with the properties described below}:
\begin{itemize}
    \item Summing up the vectors
    \item Multiplication by a number
\end{itemize}
\begin{qt}
    Consider the set of vectors, elements of the linear space L
    $$
\left\{\mathbf{a}_{1}, \mathbf{a}_{2}, \ldots, \mathbf{a}_{n}\right\}=\left\{\mathbf{a}_{i} | i=1, \ldots, n\right\}
$$
and the set of real numbers $k_{1}, k_{2}, \ldots k_{n} .$ Vector
$$
\mathbf{k}=\sum_{i=1}^{n} k^{i} \mathbf{a}_{i}=\mathbf{k}^{i} \mathbf{a}_{i}=0\Longrightarrow \sum_{i=1}^{n}\left(k^{i}\right)^{2}=0
$$
then vectors $\left\{\mathbf{a}_{\mathbf{i}}, i=1, \ldots, n\right\}$ are called \textbf{linearly independent}. The last condition means that no one of the coefficients $k_{i}$ can be different from zero.
\end{qt}
For example, in 2D, two vectors are linearly dependent if and only if they are parallel; in 3D, three vectors are linearly dependent if and only if they belong to the same plane, etc.
\begin{defi}
        The maximal number of linearly independent elements of the linear space $L$ is called its dimension. It proves useful to denote $L_{D}$ a linear space of dimension $D .$
\end{defi}
\begin{thm}
Consider a $D$-dimensional linear space $L_{D}$ and the set of linearly independent vectors $\mathbf{e}_{i}=\left(\mathbf{e}_{1}, \mathbf{e}_{2}, \ldots, \mathbf{e}_{D}\right) .$ Then, for any vector a one can write
\begin{equation}
    \mathbf{a}=\sum_{i=1}^{D} a^{i} \mathbf{e}_{i}=a^{i} \mathbf{e}_{i}
    \label{vector-basis}
\end{equation}
where the coefficients $a^{i}$ are defined in a unique way.
\end{thm}
\bluep{The coefficients $a^{i}$ are called components or \textbf{contravariant components of the vector $\mathbf{a}$}}.The word “contravariant” here means that the components $a^i$ have upper indices.

\subsection{Direct product of the two linear spaces}
Let's consider the example of phase space in the classic mechanics. The coordinate system in the linear space $L_{D}$ consists of the initial point $O$ and the basis $\mathbf{e}_{i} .$ The position of a point $P$ can be characterized by \textbf{its position vector or radius vector $\mathbf{r}=\overrightarrow{O P}=x^{i} \mathbf{e}_{i}$}.

If the phase space is describing one particle, the space is composed of the radius vectors $\mathbf{r}$ and velocities $\mathbf{v}$ of the particle:
$$
\mathbf{r}=x^{i} \mathbf{e}_{i}, \quad \mathbf{v}=v^{j} \mathbf{f}_{j}
$$
The two set of bases can be related and independent. This example is a particular case of the linear space which is called \redp{a direct product
of the two linear spaces}. The element of the direct product of the two linear spaces $L_{D_{1}}$ and $L_{D_{2}}$ (\textbf{they can have different dimensions}) is the ordered set of the elements of each of the two spaces $L_{D_{1}}$ and $L_{D_{2}} .$
\begin{qt}
    The notation for the basis in the case of configuration space is $\mathbf{e}_{i} \otimes \mathbf{f}_{j}$. Hence, the state of the point-like particle in the phase space is characterized by the element of this linear space, which can be presented as:
    $$
x^{i} v^{j} \mathbf{e}_{i} \otimes \mathbf{f}_{j}
$$
In general, one can define the space that is a direct product of several linear spaces with different individual basis sets $\mathbf{e}_{i}$ each. In this case, we will have $\mathbf{e}_{i}^{(1)}, \mathbf{e}_{i}^{(2)}, \ldots$ $\mathbf{e}_{i}^{(N)} .$ The basis in the direct product space will be
$$
\mathbf{e}_{i_{1}}^{(1)} \otimes \mathbf{e}_{i_{2}}^{(2)} \otimes \ldots \otimes \mathbf{e}_{i_{N}}^{(N)}
$$
and the element becomes
$$
T^{i_{1} i_{2} \ldots i_{N}} \mathbf{e}_{i_{1}}^{(1)} \otimes \mathbf{e}_{i_{2}}^{(2)} \otimes \ldots \otimes \mathbf{e}_{i_{N}}^{(N)}
$$
\end{qt}
\subsection{Vector basis and its transformation}
Let us start from the components of the vector, which were defined in (\ref{vector-basis}). Consider, along with the original basis $\mathbf{e}_{i},$ another basis $\mathbf{e}_{i}^{\prime} .$ since each vector of the new basis belongs to the same space, it can be expanded using the original basis as
\begin{equation}
\mathbf{e}_{i}^{\prime}=\wedge_{i^{\prime}}^{j} \mathbf{e}_{j}
\label{basis-transform}
\end{equation}
and
$$
\mathbf{a}=a^{i} \mathbf{e}_{i}=a^{j^{\prime}} \mathbf{e}_{j^{\prime}}=a^{j^{\prime}} \wedge_{j^{\prime}}^{i} \mathbf{e}_{i}
$$
\begin{qt}
\begin{equation}
    a^{i}=a^{j^{\prime}} \wedge_{j^{\prime}}^{i}
    \label{cotravariant-coord-transform}
\end{equation}
\end{qt}

Similarly, we can make inverse transformation:
$$
a^{k^{\prime}}=\left(\wedge^{-1}\right)_{l}^{k^{\prime}} a^{l}
$$
and
\[
\left(\wedge^{-1}\right)_{l}^{k^{\prime}} \cdot \wedge_{i^{\prime}}^{l}=\delta_{i^{\prime}}^{k^{\prime}} \quad \text { and } \quad \wedge_{i^{\prime}}^{l} \cdot\left(\wedge^{-1}\right)_{k}^{i^{\prime}}=\delta_{k}^{l}
\]
\begin{qt}
Taking the partial derivatives, we arrive at the relations
\[
\wedge_{j^{\prime}}^{i}=\frac{\partial x^{i}}{\partial x^{j^{\prime}}} \quad \text { and } \quad\left(\wedge^{-1}\right)_{l}^{k^{\prime}}=\frac{\partial x^{k^{\prime}}}{\partial x^{l}}
\]
and
$$
\left(\wedge^{-1}\right)_{l}^{k^{\prime}} \cdot \wedge_{k^{\prime}}^{i}=\frac{\partial x^{k^{\prime}}}{\partial x^{l}} \frac{\partial x^{i}}{\partial x^{k^{\prime}}}=\frac{\partial x^{i}}{\partial x^{l}}=\delta_{l}^{i}
$$
is nothing but the chain rule for partial derivatives.
\end{qt}

\subsection{Scalar, vector, and tensor fields}
\begin{defi}
        Function $\varphi(x)$ is called scalar field or simply scalar if it does not transform under the change of coordinates
        \begin{equation}
\varphi(x)=\varphi^{\prime}\left(x^{\prime}\right)
\end{equation}
\end{defi}
Let us give a clarifying example in 1D. Consider a function
$$
y=x^2
$$
Now, let us change the variables 
$$
x^{\prime}=x+1
$$
The function $y=\left(x^{\prime}\right)^{2},$ obviously, represents another parabola. \bluep{In order to preserve the plot intact, we need to modify the form of the function, that is, to go from $\varphi$ to $\varphi^{\prime}$.} The new function $y^{\prime}=\left(x^{\prime}-1\right)^{2}$ will represent the original parabola,because the change of the variable is completely compensated by the change of the form of the function.
\begin{mybox}
\begin{center}
    Discuss whether the three numbers temperature $T(x)$, pressure $p(x)$ and density $\rho(x)$ form a contravariant vector
\end{center}
\end{mybox}
\begin{mybox2}
We can only form contravariant vector if the numbers transform by following the rule (\ref{cotravariant-coord-transform}). Since these numbers are scalar fields, it transforms like $T(\mathbf{r})=T^{\prime}(\mathbf{r}^{\prime})$. Thus, these three parameters can not form a contravariant vector.
\end{mybox2}
\begin{example}
From the definition above we know $\varphi^{\prime}(x) \neq \varphi(x)$ and $\varphi\left(x^{\prime}\right) \neq \varphi(x)$. Let us calculate these quantities explicitly for the special case of infinitesimal transformation $x^{\prime i}=x^{i}+\xi^{i}$ where $\xi$ are constant coefficients. Now we have
$$
\varphi\left(x^{\prime}\right)=\varphi\left(x+\xi\right)\overset{Taylor}{=}\varphi(x)+\frac{\partial \varphi}{\partial x^{i}} \xi^{i}
$$
and,
$$
\varphi^{\prime}\left(x^{i}\right)=\varphi^{\prime}\left(x^{i}-\xi^{i}\right)=\varphi^{\prime}\left(x^{\prime}\right)-\frac{\partial \varphi^{\prime}}{\partial x^{i^{\prime}}} \cdot \xi^{i}
$$
rewrite the two equations above, we find:
$$
\frac{\partial \varphi^{\prime}}{\partial x^{\prime i}}=\frac{\varphi^{\prime}\left(x^{\prime i}\right)-\varphi^{\prime}\left(x^{i}-\xi^{i}\right)}{\xi^i}
$$
$$
\frac{\partial \varphi}{\partial x^{i}}=\frac{\varphi(x^{\prime i})-\varphi(x^i)}{\xi^i}
$$
At the limit of $\xi\rightarrow0$, we have
$$
\frac{\partial \varphi^{\prime}}{\partial x^{\prime i}}=\frac{\partial \varphi(x)}{\partial x^{i}}+\mathcal{O}(\xi)
$$
As mentioned above, 
$$
\varphi^{\prime}\left(x^{i}\right)=\varphi^{\prime}\left(x^{\prime}\right)-\frac{\partial \varphi^{\prime}}{\partial x^{\prime i}} \cdot \xi^{i}\\
=\varphi^{\prime}\left(x^{\prime}\right)-\frac{\partial \varphi(x)}{\partial x^{i}}\cdot\xi^i
$$
Since $\varphi(x)=\varphi^{\prime}\left(x^{\prime}\right)$, we have
$$
\varphi^{\prime}(x)=\varphi(x)-\xi^{i} \partial_{i} \varphi
$$
\textbf{where we have introduced a useful notation $\partial_{i}=\partial / \partial x^{i}$.}
\end{example}
\textbf{For the vector field, we have the following rule for the coordinate transformation}. The set of three functions $\left\{a^{i}(x)\right\}=\left\{a^{1}(x), a^{2}(x), a^{3}(x)\right\}$ forms contravariant vector field (or simply vector field) if they transform, under the change of coordinates $\left\{x^{i}\right\} \rightarrow\left\{x^{\prime} j\right\},$ as
\begin{qt}
\begin{equation}
a^{j^{\prime}}\left(x^{\prime}\right)=\frac{\partial x^{j^{\prime}}}{\partial x^{i}} \cdot a^{i}(x)
\end{equation}
\end{qt}
\bluep{The components of the vector in a given geometrical point of space modify under the coordinate transformation, while the scalar field does not.}The scalar and vector fields can be considered as examples of the more general objects called tensors. Tensors are also defined through their transformation rules.
\begin{qt}
The set of $3^n$ functions $\left\{a^{i_{1} \ldots i_{n}}(x)\right\}$ is called a contravariant tensor of rank $n,$ if these functions transform, under $x^{i} \rightarrow x^{i},$ as
\begin{equation}
a^{i_{1}^{i} \ldots i_{n}^{\prime}}\left(x^{\prime}\right)=\frac{\partial x^{i_{1}^{\prime}}}{\partial x^{j_{1}}} \ldots \frac{\partial x^{i_{n}^{\prime}}}{\partial x^{j_{n}}} a^{j_{1} \ldots j_{n}}(x)
\end{equation}
\end{qt}

\subsection{Orthonormal Basis and Cartesian Coordiantes}
The scalar product of two vectors $\mathbf{a}$ and $\mathbf{b}$ in 3D is defined in a ususal way,
\begin{equation}
(\mathbf{a}, \mathbf{b})=\mathbf{a}\cdot\mathbf{b}=|\mathbf{a}| \cdot|\mathbf{b}| \cdot \cos \theta
\end{equation}
Special orthonormal basis $\left\{\hat{\mathbf{n}}_{a}\right\}$ is the one with
\begin{equation}
\left(\hat{\mathbf{n}}_{a}, \hat{\mathbf{n}}_{b}\right)=\delta_{a b}=\left\{\begin{array}{l}
{1 \text { if } a=b} \\
{0 \text { if } a \neq b}
\end{array}\right.
\end{equation}
\begin{example}
Making transformations of the basis vectors, verify that the change of coordinates
$$
x^{\prime}=\frac{x+y}{\sqrt{2}}+3, \quad y^{\prime}=\frac{x-y}{\sqrt{2}}-5
$$
does not modify the type of coordinates $x^{\prime}, y^{\prime},$ which remains Cartesian.
\textbf{Solution}:
$$
x^{\prime}=\frac{x+y}{\sqrt{2}}+3, \quad y^{\prime}=\frac{x-y}{\sqrt{2}}-5
$$
The change of initial point $(0,0) \rightarrow(3,-5)$ does not have relation to the change of basis. Then
$$
\begin{aligned}
x^{\prime} \hat{i}^{\prime}+y^{\prime} \hat{j}^{\prime} &=\left(\frac{x+y}{\sqrt{2}}\right) \hat{i}^{\prime}+\left(\frac{x-y}{\sqrt{2}}\right) \hat{j}^{\prime} \\
&=\frac{x}{\sqrt{2}}\left(\hat{i}^{\prime}+\hat{j}^{\prime}\right)+\frac{y}{\sqrt{2}}\left(\hat{i}^{\prime}-\hat{j}^{\prime}\right)=x \hat{i}+y \hat{j}
\end{aligned}
$$
Thus, $\hat{i}=\frac{1}{\sqrt{2}}\left(\hat{i}^{\prime}+\hat{j}^{\prime}\right), \hat{j}=\frac{1}{\sqrt{2}}\left(\hat{i}^{\prime}-\hat{j}^{\prime}\right) .$ Obviously, $\hat{i}^{2}=\hat{j}^{2}=1$ and $\hat{i} \cdot \hat{j}=0$
\end{example}
Now we can introduce a conjugated covariant basis.
\begin{qt}
Consider basis $\left\{\mathbf{e}_{i}\right\} .$ The conjugated basis is defined as a set of vectors $\left\{\mathbf{e}^{j}\right\}$ which satisfy the relations
\begin{equation}
\mathbf{e}_{i} \cdot \mathbf{e}^{j}=\delta_{i}^{j}
\end{equation}
The special property of the orthonormal basis is that $\hat{\mathbf{n}}^{a}=\hat{\mathbf{n}}_{a}$.

Any vector a can be expanded using the conjugated basis $\mathbf{a}=a_{i} \mathbf{e}^{i} .$ \redp{The coefficients $a_{i}$ are called covariant components of the vector $\mathbf{a}$}.
\end{qt}
In the case of covariant vector components, the transformation is done by means of the matrix inverse to the one for the contravariant components.
\begin{thm}
If we change the basis of the coordinate system from $\mathbf{e}_{i}$ to $\mathbf{e}_{i}^{\prime},$ then the covariant components of the vector a transform as
\begin{equation}
a_{i}^{\prime}=\frac{\partial x^{j}}{\partial x^{i}} a_{j}
\end{equation}
\end{thm}

 The set of three functions $\left\{A_{i}(x)\right\}$ forms a covariant vector field, if they transform from one coordinate system to another one as
 \begin{equation}
A_{i}^{\prime}\left(x^{\prime}\right)=\frac{\partial x^{j}}{\partial x^{i}} A_{j}(x)
\end{equation}
The set of $3^{n}$ functions $\left\{A_{i_{1} i_{2} \ldots i_{n}}(x)\right\}$ form a covariant tensor of rank $n$ if they transform from one coordinate system to another as
\begin{equation}
A_{i_{1} i_{2} \ldots i_{n}}^{\prime}\left(x^{\prime}\right)=\frac{\partial x^{j_{1}}}{\partial x^{i_{1}}} \frac{\partial x^{j_{2}}}{\partial x^{i_{2}}} \cdots \frac{\partial x^{j_{n}}}{\partial x^{n_{n}}} A_{j_{1} j_{2} \ldots j_{n}}(x)
\end{equation}
In general
\begin{qt}
The set of $3^{n+m}$ functions $\left\{B_{i_{1} \ldots i_{n}} j_{1 \ldots j_{n}}(x)\right\}$ forms the tensor of the type $(m, n),$ if these functions transform, under the change of coordinate basis, as
\begin{equation}
B_{i_{1}^{\prime} \ldots i_{n}^{\prime}} ^{j_{1}^{\prime} \ldots j_{m}^{\prime}}\left(x^{\prime}\right)=\frac{\partial x^{j^{\prime} 1}}{\partial x^{l_{1}}} \cdots \frac{\partial x^{j_{m}^{\prime} m}}{\partial x^{l_{m}}} \frac{\partial x^{k_{1}}}{\partial x^{\prime i_{1}}} \cdots \frac{\partial x^{k_{n}}}{\partial x^{\prime i_{n}}} B_{k_{1} \ldots k_{n}}^{l_{1} \ldots l_{m}}(x)
\end{equation}
Other possible names are the mixed tensor of covariant rank $n$ and contravariant rank $m,$ or simply $(m, n)$ -tensor.
\end{qt}
\textbf{Tensors are important due to the fact that they offer the coordinate-independent description of geometrical and physical laws.} The following example shows this observation:
\begin{example}
For an arbitrary $\mathbf{a}(x)=a^{i}(x) \mathbf{e}_{i}$ we have
$$
a^{j^{\prime}}\left(x^{\prime}\right)=\frac{\partial x^{j^{\prime}}}{\partial x^{i}} a^{i}(x), \quad \mathbf{e}_{j^{\prime}}\left(x^{\prime}\right)=\mathbf{e}_{k}(x) \frac{\partial x^{k}}{\partial x^{j^{\prime}}}
$$
Then
$$
a^{j^{\prime}}\left(x^{\prime}\right) \mathbf{e}_{j^{\prime}}\left(x^{\prime}\right)=\frac{\partial x^{j^{\prime}}}{\partial x^{i}} a^{i}(x) \mathbf{e}_{k}(x) \frac{\partial x^{k}}{\partial x^{j^{\prime}}}=\delta_{l}^{k} a^{i}(x) \mathbf{e}_{k}(x)=a^{i}(x) \mathbf{e}_{i}(x)
$$
\end{example}

If the Kronecker symbol transforms as a mixed $(1,1)$ tensor,
\begin{qt}
\begin{equation}
\delta_{j^{\prime}}^{i^{\prime}}=\frac{\partial x^{i^{\prime}}}{\partial x^{k}} \frac{\partial x^{l}}{\partial x^{j^{\prime}}} \delta_{l}^{k}=\frac{\partial x^{i^{\prime}}}{\partial x^{j^{\prime}}}
\end{equation}
\end{qt}
then in any coordinates $x^i$ it has the same form 
$$
\delta_{j}^{i}=\left\{\begin{array}{l}
{1 \text { if } i=j} \\
{0 \text { if } i \neq j}
\end{array}\right.
$$
\textbf{This property is very important, as it enables us to use the Kronecker symbol in any coordinates}

\begin{example}
Show that the product $A^{i}(x) B_{j}(x)$ of covariant and contravariant vectors transforms as a $(1,1)$ -type mixed tensor.
$$
A^{i^{\prime}}\left(x^{\prime}\right) A_{j^{\prime}}\left(x^{\prime}\right)=\frac{\partial x^{i^{\prime}}}{\partial x^{k}} A^{k}(x) \frac{\partial x^{l}}{\partial x^{j^{\prime}}} B_{l}(x)=\frac{\partial x^{i^{\prime}}}{\partial x^{k}} \frac{\partial x^{l}}{\partial x^{j^{\prime}}} A^{k}(x) B_{l}(x)
$$
\end{example}
